# ğŸ”€ AI Gateway

> Intelligent LLM Router with semantic caching, deployed on GKE Autopilot.

A production-ready AI Gateway that routes requests to multiple LLM providers, implements semantic caching, and provides observability. Built as a learning project for GKE/K8s while applying AI Engineering skills.

## ğŸ¯ What It Does

- **Smart Routing**: Routes requests to optimal model based on cost/latency/task
- **Semantic Cache**: Cache similar prompts using embeddings (save $$$)
- **Multi-Provider**: OpenAI, Gemini, Anthropic, Groq, etc.
- **Observability**: Logs, metrics, cost tracking per request
- **Rate Limiting**: Protect against abuse
- **Fallbacks**: Auto-retry with different provider on failure

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚â”€â”€â”€â”€â–¶â”‚  AI Gateway  â”‚â”€â”€â”€â”€â–¶â”‚  LLM APIs    â”‚
â”‚              â”‚     â”‚  (TypeScript)â”‚     â”‚ (OpenAI,     â”‚
â”‚              â”‚â—€â”€â”€â”€â”€â”‚              â”‚â—€â”€â”€â”€â”€â”‚  Gemini...)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                     â”‚   Redis     â”‚
                     â”‚ (semantic   â”‚
                     â”‚   cache)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### K8s Architecture (GKE Autopilot)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GKE Autopilot                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Gateway    â”‚  â”‚  Gateway    â”‚  â”‚   Redis     â”‚ â”‚
â”‚  â”‚  Pod (HPA)  â”‚  â”‚  Pod (HPA)  â”‚  â”‚ StatefulSet â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                         â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                   â”‚ LoadBalancerâ”‚                  â”‚
â”‚                   â”‚  (ingress)  â”‚                  â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose | Why |
|------------|---------|-----|
| **TypeScript** | Language | Type safety, your comfort zone |
| **Bun** | Runtime | Fast, built-in TypeScript, good DX |
| **Hono** | Framework | Lightweight, edge-ready, fast |
| **Vercel AI SDK** | LLM abstraction | Multi-provider support, streaming |

### Infrastructure
| Technology | Purpose | Why |
|------------|---------|-----|
| **Redis** | Cache + Vectors | Simple, fast, RediSearch for similarity |
| **Docker** | Containerization | Standard |
| **GKE Autopilot** | Orchestration | Learning goal, zero node management |
| **Artifact Registry** | Image storage | GCP native, secure |

### Observability
| Technology | Purpose | Why |
|------------|---------|-----|
| **Pino** | Logging | Fast, structured JSON logs |
| **OpenTelemetry** | Metrics/Tracing | Standard, optional |

## ğŸ“ Project Structure

```
ai-gateway/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.ts           # /v1/chat/completions
â”‚   â”‚   â”œâ”€â”€ health.ts         # /health, /ready
â”‚   â”‚   â””â”€â”€ metrics.ts        # /metrics
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts      # Model selection logic
â”‚   â”‚   â”‚   â””â”€â”€ rules.ts      # Routing rules config
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts      # Cache interface
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.ts # Generate embeddings
â”‚   â”‚   â”‚   â””â”€â”€ redis.ts      # Redis client
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â”œâ”€â”€ index.ts      # Provider interface
â”‚   â”‚       â”œâ”€â”€ openai.ts     # OpenAI adapter
â”‚   â”‚       â”œâ”€â”€ gemini.ts     # Gemini adapter
â”‚   â”‚       â””â”€â”€ anthropic.ts  # Anthropic adapter
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ logging.ts        # Request logging
â”‚       â””â”€â”€ rateLimit.ts      # Rate limiting
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ gateway.yaml          # Deployment + Service
â”‚   â”œâ”€â”€ redis.yaml            # StatefulSet + Service
â”‚   â”œâ”€â”€ configmap.yaml        # Routing config
â”‚   â”œâ”€â”€ secret.yaml           # API keys (template)
â”‚   â””â”€â”€ hpa.yaml              # Autoscaling
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yaml       # Local dev (gateway + redis)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ğŸ”‘ Prerequisites

### API Keys Needed
- [ ] OpenAI API Key (`OPENAI_API_KEY`)
- [ ] Google AI API Key (`GOOGLE_API_KEY`) - for Gemini
- [ ] (Optional) Anthropic API Key (`ANTHROPIC_API_KEY`)
- [ ] (Optional) Groq API Key (`GROQ_API_KEY`)

### Tools
- [ ] Bun installed (`curl -fsSL https://bun.sh/install | bash`)
- [ ] Docker Desktop
- [ ] `gcloud` CLI configured
- [ ] `kubectl` installed
- [ ] GCP Project with billing enabled

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/CarlosPProjects/ai-gateway.git
cd ai-gateway

# Install dependencies
bun install

# Copy env file
cp .env.example .env
# Edit .env with your API keys

# Start Redis (local)
docker-compose up -d redis

# Run dev server
bun run dev

# Test
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello!"}]}'
```

## ğŸ“š Learning Goals

This project teaches:

### Kubernetes / GKE
- [x] Deployments and ReplicaSets
- [x] Services (ClusterIP vs LoadBalancer)
- [x] StatefulSets (for Redis)
- [x] ConfigMaps and Secrets
- [x] Horizontal Pod Autoscaler (HPA)
- [x] GKE Autopilot specifics
- [x] Artifact Registry workflow

### AI Engineering
- [x] Multi-provider LLM abstraction
- [x] Semantic caching with embeddings
- [x] Cost optimization strategies
- [x] Production patterns for AI services

## ğŸ”— Resources

- [Hono Documentation](https://hono.dev/)
- [Vercel AI SDK](https://sdk.vercel.ai/)
- [GKE Autopilot Guide](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview)
- [LiteLLM](https://github.com/BerriAI/litellm) - Inspiration
- [Portkey](https://portkey.ai/) - Inspiration

## ğŸ“„ License

MIT

---

Built by [Carlos Garavito](https://github.com/CarlosPProjects) as a Master's Cloud Computing project.
