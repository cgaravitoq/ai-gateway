# ğŸ”€ AI Gateway

> Intelligent LLM Router with semantic caching, deployed on GKE Autopilot.

A production-ready AI Gateway that routes requests to multiple LLM providers, implements semantic caching, and provides observability. Built as a learning project for GKE/K8s while applying AI Engineering skills.

## ğŸ¯ What It Does

- **Smart Routing**: Routes requests to optimal model based on cost/latency/task
- **Semantic Cache**: Cache similar prompts using embeddings (save $$$)
- **Multi-Provider**: OpenAI, Gemini, Anthropic, Groq, etc.
- **Observability**: Logs, metrics, cost tracking per request
- **Rate Limiting**: Protect against abuse
- **Fallbacks**: Auto-retry with different provider on failure

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚â”€â”€â”€â”€â–¶â”‚  AI Gateway  â”‚â”€â”€â”€â”€â–¶â”‚  LLM APIs    â”‚
â”‚              â”‚     â”‚  (TypeScript)â”‚     â”‚ (OpenAI,     â”‚
â”‚              â”‚â—€â”€â”€â”€â”€â”‚              â”‚â—€â”€â”€â”€â”€â”‚  Gemini...)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                     â”‚   Redis     â”‚
                     â”‚ (semantic   â”‚
                     â”‚   cache)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### K8s Architecture (GKE Autopilot)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GKE Autopilot                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Gateway    â”‚  â”‚  Gateway    â”‚  â”‚   Redis     â”‚ â”‚
â”‚  â”‚  Pod (HPA)  â”‚  â”‚  Pod (HPA)  â”‚  â”‚ StatefulSet â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                          â”‚                         â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                   â”‚ LoadBalancerâ”‚                  â”‚
â”‚                   â”‚  (ingress)  â”‚                  â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose | Why |
|------------|---------|-----|
| **TypeScript** | Language | Type safety, your comfort zone |
| **Bun** | Runtime | Fast, built-in TypeScript, good DX |
| **Hono** | Framework | Lightweight, edge-ready, fast |
| **Vercel AI SDK** | LLM abstraction | Multi-provider support, streaming |

### Infrastructure
| Technology | Purpose | Why |
|------------|---------|-----|
| **Redis** | Cache + Vectors | Simple, fast, RediSearch for similarity |
| **Docker** | Containerization | Standard |
| **GKE Autopilot** | Orchestration | Learning goal, zero node management |
| **Artifact Registry** | Image storage | GCP native, secure |

### Observability
| Technology | Purpose | Why |
|------------|---------|-----|
| **Pino** | Logging | Fast, structured JSON logs |
| **OpenTelemetry** | Metrics/Tracing | Standard, optional |

## ğŸ“ Project Structure

```
ai-gateway/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Entry point
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.ts           # /v1/chat/completions
â”‚   â”‚   â”œâ”€â”€ health.ts         # /health, /ready
â”‚   â”‚   â””â”€â”€ metrics.ts        # /metrics
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ router/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts      # Model selection logic
â”‚   â”‚   â”‚   â””â”€â”€ rules.ts      # Routing rules config
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts      # Cache interface
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.ts # Generate embeddings
â”‚   â”‚   â”‚   â””â”€â”€ redis.ts      # Redis client
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â”œâ”€â”€ index.ts      # Provider interface
â”‚   â”‚       â”œâ”€â”€ openai.ts     # OpenAI adapter
â”‚   â”‚       â”œâ”€â”€ gemini.ts     # Gemini adapter
â”‚   â”‚       â””â”€â”€ anthropic.ts  # Anthropic adapter
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ logging.ts        # Request logging
â”‚       â””â”€â”€ rateLimit.ts      # Rate limiting
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ namespace.yaml        # ai-gateway namespace
â”‚   â”œâ”€â”€ gateway-deployment.yaml # Gateway Deployment (2 replicas)
â”‚   â”œâ”€â”€ gateway-service.yaml  # ClusterIP Service (80 â†’ 3000)
â”‚   â”œâ”€â”€ redis-statefulset.yaml # Redis Stack StatefulSet
â”‚   â”œâ”€â”€ redis-service.yaml    # Headless Service for Redis
â”‚   â”œâ”€â”€ configmap.yaml        # Non-secret config
â”‚   â”œâ”€â”€ secret.yaml           # API keys (template)
â”‚   â”œâ”€â”€ hpa.yaml              # Autoscaling (2â€“10 pods)
â”‚   â”œâ”€â”€ network-policy.yaml   # Network isolation rules
â”‚   â”œâ”€â”€ ingress.yaml          # External LoadBalancer
â”‚   â””â”€â”€ kustomization.yaml    # Kustomize entrypoint
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yaml       # Local dev (gateway + redis)
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## ğŸ”‘ Prerequisites

### API Keys Needed
- [ ] OpenAI API Key (`OPENAI_API_KEY`)
- [ ] Google AI API Key (`GOOGLE_API_KEY`) - for Gemini
- [ ] (Optional) Anthropic API Key (`ANTHROPIC_API_KEY`)
- [ ] (Optional) Groq API Key (`GROQ_API_KEY`)

### Tools
- [ ] Bun installed (`curl -fsSL https://bun.sh/install | bash`)
- [ ] Docker Desktop
- [ ] `gcloud` CLI configured
- [ ] `kubectl` installed
- [ ] GCP Project with billing enabled

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/CarlosPProjects/ai-gateway.git
cd ai-gateway

# Install dependencies
bun install

# Copy env file
cp .env.example .env
# Edit .env with your API keys

# Start Redis (local)
docker-compose up -d redis

# Run dev server
bun run dev

# Test
curl -X POST http://localhost:3000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello!"}]}'
```

## â˜¸ï¸ Deploying to GKE Autopilot

### Prerequisites

- [Google Cloud SDK (`gcloud`)](https://cloud.google.com/sdk/docs/install) configured with a project
- [`kubectl`](https://kubernetes.io/docs/tasks/tools/) installed
- [Docker](https://docs.docker.com/get-docker/) installed
- A GCP project with billing enabled and the following APIs enabled:
  - Kubernetes Engine API
  - Artifact Registry API

### 1. Create GKE Autopilot Cluster

```bash
# Set your project
export PROJECT_ID=your-gcp-project-id
export REGION=us-central1

gcloud config set project $PROJECT_ID

# Create cluster (if not already created)
gcloud container clusters create-auto ai-gateway-cluster \
  --region=$REGION

# Get credentials
gcloud container clusters get-credentials ai-gateway-cluster \
  --region=$REGION
```

### 2. Create Artifact Registry Repository

```bash
# Create Docker repository
gcloud artifacts repositories create ai-gateway \
  --repository-format=docker \
  --location=$REGION \
  --description="AI Gateway container images"

# Configure Docker auth
gcloud auth configure-docker ${REGION}-docker.pkg.dev
```

### 3. Build & Push Image

```bash
# Build the image
docker build -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/ai-gateway/ai-gateway:latest .

# Push to Artifact Registry
docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/ai-gateway/ai-gateway:latest
```

### 4. Configure Secrets

```bash
# Create the secret with real API keys (do NOT commit these!)
kubectl create namespace ai-gateway

kubectl create secret generic gateway-secrets \
  --namespace=ai-gateway \
  --from-literal=OPENAI_API_KEY=sk-... \
  --from-literal=ANTHROPIC_API_KEY=sk-ant-... \
  --from-literal=GOOGLE_API_KEY=AIza... \
  --from-literal=OPENAI_EMBEDDING_API_KEY=sk-...
```

### 5. Deploy with Kustomize

```bash
# Update the image reference to your actual registry
cd k8s
kustomize edit set image \
  REGION-docker.pkg.dev/PROJECT_ID/ai-gateway/ai-gateway=${REGION}-docker.pkg.dev/${PROJECT_ID}/ai-gateway/ai-gateway:latest

# Apply all manifests (skip secret.yaml since we created it manually above)
kubectl apply -k .
```

### 6. Verify Deployment

```bash
# Check pods are running
kubectl get pods -n ai-gateway

# Check services
kubectl get svc -n ai-gateway

# Get the external IP (may take a minute for LoadBalancer)
kubectl get svc ai-gateway-lb -n ai-gateway -w

# Test the health endpoint
export GATEWAY_IP=$(kubectl get svc ai-gateway-lb -n ai-gateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
curl http://$GATEWAY_IP/health

# Test a chat completion
curl -X POST http://$GATEWAY_IP/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello!"}]}'
```

### Kubernetes Manifests Overview

All manifests live in `k8s/` and are managed via [Kustomize](https://kustomize.io/):

| File | Resource | Description |
|------|----------|-------------|
| `namespace.yaml` | Namespace | `ai-gateway` namespace |
| `configmap.yaml` | ConfigMap | Non-secret config (Redis URL, cache settings, routing) |
| `secret.yaml` | Secret | API keys template (use `kubectl create secret` for real values) |
| `gateway-deployment.yaml` | Deployment | Gateway pods (2 replicas, probes, security context) |
| `gateway-service.yaml` | Service | ClusterIP service (port 80 â†’ 3000) |
| `redis-statefulset.yaml` | StatefulSet | Redis Stack with persistent storage |
| `redis-service.yaml` | Service | Headless service for stable Redis DNS |
| `hpa.yaml` | HPA | Autoscale 2â€“10 replicas at 70% CPU |
| `network-policy.yaml` | NetworkPolicy | Gateway â†” Redis isolation, Redis locked down |
| `ingress.yaml` | Service (LB) | External LoadBalancer for public access |
| `kustomization.yaml` | Kustomize | Ties all resources together |

## ğŸ“š Learning Goals

This project teaches:

### Kubernetes / GKE
- [x] Deployments and ReplicaSets
- [x] Services (ClusterIP vs LoadBalancer)
- [x] StatefulSets (for Redis)
- [x] ConfigMaps and Secrets
- [x] Horizontal Pod Autoscaler (HPA)
- [x] GKE Autopilot specifics
- [x] Artifact Registry workflow

### AI Engineering
- [x] Multi-provider LLM abstraction
- [x] Semantic caching with embeddings
- [x] Cost optimization strategies
- [x] Production patterns for AI services

## ğŸ”— Resources

- [Hono Documentation](https://hono.dev/)
- [Vercel AI SDK](https://sdk.vercel.ai/)
- [GKE Autopilot Guide](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview)
- [LiteLLM](https://github.com/BerriAI/litellm) - Inspiration
- [Portkey](https://portkey.ai/) - Inspiration

## ğŸ“„ License

MIT

---

Built by [Carlos Garavito](https://github.com/CarlosPProjects) as a Master's Cloud Computing project.
