# ── Server ──────────────────────────────────────────────────
PORT=3000
NODE_ENV=development
LOG_LEVEL=info

# ── LLM Provider API Keys ──────────────────────────────────
# OpenAI is required (also used for embedding generation)
OPENAI_API_KEY=sk-...
# Optional — enables Anthropic (Claude) models
ANTHROPIC_API_KEY=sk-ant-...
# Optional — enables Google (Gemini) models
GOOGLE_API_KEY=AIza...

# ── Redis / Cache ──────────────────────────────────────────
REDIS_URL=redis://localhost:6379
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600
# Cosine distance threshold for cache hits (lower = stricter)
# 0.15 ≈ 85% similarity. Set to 0 to require exact matches.
CACHE_SIMILARITY_THRESHOLD=0.15

# ── Embedding Model ────────────────────────────────────────
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# ── Routing ────────────────────────────────────────────────
# Strategy: cost | latency | balanced | capability
ROUTING_STRATEGY=balanced
ROUTING_TIMEOUT_MS=30000
ROUTING_MAX_RETRIES=2
ROUTING_RETRY_BACKOFF_MS=500
# EMA smoothing factor for latency tracking (0-1, higher = more reactive)
ROUTING_LATENCY_ALPHA=0.3
# Rolling window size for latency samples
ROUTING_LATENCY_WINDOW=100

# ── Rate Limiting (token bucket) ───────────────────────────
RATE_LIMIT_ENABLED=true
RATE_LIMIT_MAX_TOKENS=60
RATE_LIMIT_REFILL_RATE=1
# Per-provider overrides (optional)
# RATE_LIMIT_OPENAI_MAX_TOKENS=60
# RATE_LIMIT_OPENAI_REFILL_RATE=1
# RATE_LIMIT_ANTHROPIC_MAX_TOKENS=40
# RATE_LIMIT_ANTHROPIC_REFILL_RATE=0.67
# RATE_LIMIT_GOOGLE_MAX_TOKENS=60
# RATE_LIMIT_GOOGLE_REFILL_RATE=1

# ── Timeouts (ms) — per-provider LLM request timeouts ─────
TIMEOUT_OPENAI_MS=30000
TIMEOUT_ANTHROPIC_MS=60000
TIMEOUT_GOOGLE_MS=30000

# ── OpenTelemetry (optional) ──────────────────────────────
# Set to "true" to enable tracing (disabled by default)
# OTEL_ENABLED=true
# OTEL_SERVICE_NAME=ai-gateway
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318
